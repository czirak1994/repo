import pandas as pd
from openpyxl import load_workbook
from datetime import datetime


def process_sheet(file_path, sheet_name):
    # Load the workbook with data_only=True to get the calculated values
    workbook = load_workbook(file_path, data_only=True)
    ws = workbook[sheet_name]
    # Read the entire sheet into a DataFrame
    data = []
    for row in ws.iter_rows(values_only=True):
        if any(cell is not None for cell in row):  # Skip completely empty rows
            data.append([cell for cell in row])
    # Check if there's data to convert
    if data:
        # Create a unique column name for each column
        columns = [f"Column_{i}" for i in range(len(data[0]))]
        df = pd.DataFrame(data[1:], columns=columns)
        # Convert all values to string
        df = df.applymap(
            lambda x: (
                x.strftime("%Y-%m-%d 00:00:00")
                if isinstance(x, datetime)
                else str(x) if x is not None else ""
            )
        )
        # Add a column to indicate the sheet name
        df["Sheet"] = sheet_name
        # Filter the DataFrame to include only rows from 10 to 516 (inclusive)
        # df = df.iloc[10:517]
        # Define the target date based on the current date
        target_date = datetime.now().strftime("%Y-%m-%d 00:00:00")
        # Search for the target date in the 11th row (index 0 relative to the filtered DataFrame) and skip the first occurrence
        found = False
        target_count = 0
        date_column_name = None
        for row_idx, row in df.iterrows():
            for col_idx, cell_value in enumerate(
                row
            ):  # 0th index here corresponds to the 11th original row
                if cell_value == target_date:
                    target_count += 1
                    if target_count == 2:  # Process the second occurrence
                        print(
                            f"Target date {target_date} found at column {col_idx} in sheet {sheet_name}"
                        )
                        date_column_name = df.columns[col_idx]
                        found = True
                        break
        if not found:
            print(
                f"Target date {target_date} not found twice in the 11th row of sheet {sheet_name}."
            )
            return pd.DataFrame()  # Return empty DataFrame if not found
        else:
            # Filter rows where the target date column value is not zero or NaN
            sap_nr_row_idx = df[df.apply(lambda row: row.astype(str).str.contains('SAP nr.').any(), axis=1)].index[0]
           # Filter rows where the target date column value is not zero or NaN, and only include rows below the 'SAP nr.' row
            filtered_df = df.loc[sap_nr_row_idx+0:]
            filtered_df = filtered_df[filtered_df[date_column_name].notna() & (filtered_df[date_column_name] != '0') & (filtered_df[date_column_name] != '')]
            
            # Find columns with dates in the 11th row (index 0)
            date_columns = []
            for column_name in df.columns:
                cell_value = df.iloc[0][column_name]
                try:
                    # Try to convert the value to datetime to check if it's a date
                    pd.to_datetime(cell_value)
                    date_columns.append(column_name)
                except (ValueError, TypeError):
                    continue
            print(f"Date columns in the 11th row of sheet {sheet_name}: {date_columns}")
            # Keep only the first 10 columns, the target date column, and non-date columns
            columns_to_keep_indices = [ 4, 5, 6, 9, 10]  # Example indices to keep
            columns_to_keep = [df.columns[i] for i in columns_to_keep_indices] + [
                date_column_name
            ]
            filtered_df = filtered_df[columns_to_keep]
            # Return the filtered DataFrame
            return filtered_df


# File path and sheet names
file_path = "PRODPLAN.xlsx"  # Replace with your Excel file path
sheet_names = [
    "KoVoMo szerelések",
    "MDB hegesztés",
    "Wielpütz szerelés",
]  # Replace with your sheet names
# Process each sheet separately and store the results in a dictionary
results = {}
for sheet_name in sheet_names:
    filtered_df = process_sheet(file_path, sheet_name)
    if not filtered_df.empty:
        results[sheet_name] = filtered_df
# Write the results to a single Excel file with each DataFrame on a separate sheet
with pd.ExcelWriter("combined_filtered_data.xlsx") as writer:
    for sheet_name, df in results.items():
        df.to_excel(writer, sheet_name=sheet_name, index=False)
print("All sheets processed and saved to 'combined_filtered_data.xlsx'.")

